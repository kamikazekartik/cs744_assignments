{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG11-Cifar10_ksreenivasan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamikazekartik/cs744_assignments/blob/master/project/VGG11_Cifar10_ksreenivasan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrhNaWmyAxP-"
      },
      "source": [
        "Baseline performance and timings for training LeNet on MNIST/EMNIST.\n",
        "\n",
        "Before running the notebook, go to Runtime -> Change Runtime Type in the menu and set Hardware Accelerator to GPU. **Make sure you change it back** when finished to avoid being penalized by Colab.\n",
        "\n",
        "You can use the dataset variable to decide if to run on MNIST or EMNIST (EMNIST will be slightly slower since the training data is significantly larger)\n",
        "\n",
        "Each cell runs with different precision settings\n",
        "\n",
        "Strange behavior right now:\n",
        "1. Full precision is the fastest.\n",
        "2. Half precision is about half a second slower per epoch.\n",
        "3. AMP is still slower by another whole second.\n",
        "\n",
        "Code is based on [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OWrK5JJ4GVC"
      },
      "source": [
        "import time\n",
        "import os, random\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from typing import Union, List, Dict, Any, cast\n",
        "import logging\n",
        "\n",
        "__all__ = [\n",
        "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
        "    'vgg19_bn', 'vgg19',\n",
        "]\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
        "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
        "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
        "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
        "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
        "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
        "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
        "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        features: nn.Module,\n",
        "        num_classes: int = 1000,\n",
        "        init_weights: bool = True\n",
        "    ) -> None:\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self) -> None:\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\n",
        "    layers: List[nn.Module] = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            v = cast(int, v)\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "cfgs: Dict[str, List[Union[str, int]]] = {\n",
        "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG:\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\n",
        "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
        "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\n",
        "    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
        "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\n",
        "    r\"\"\"VGG 13-layer model (configuration \"B\")\n",
        "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\n",
        "    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
        "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\n",
        "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
        "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\n",
        "    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
        "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\n",
        "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
        "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\n",
        "    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
        "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9d5Kq0U8iwo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "outputId": "b83be748-a697-4eb1-efb8-aa720afff54e"
      },
      "source": [
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "def seed_experiment(seed=0):\n",
        "    # seed = 1234\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    # TODO: Do we need deterministic in cudnn ? Double check\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(\"Seeded everything with seed: {}\".format(seed))\n",
        "\n",
        "# seed experiment\n",
        "seed_experiment(42)\n",
        "\n",
        "# Options:\n",
        "use_amp = False\n",
        "use_half_all = True\n",
        "use_half_conv = False\n",
        "use_half_lin = False\n",
        "dataset = 'Cifar10'\n",
        "PRELOAD = False # decides if we should use pytorch's dataloader or just preload into a python list\n",
        "\n",
        "# Make sure we're using a GPU, and report what GPU it is.\n",
        "# (Otherwise this would run **forever**)\n",
        "if torch.cuda.is_available():\n",
        "  print(\"using \"+torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print('No GPU available (enable it?), quitting.')\n",
        "  exit()\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# Set up dataset:\n",
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "\n",
        "class ToHalfTensor(object):\n",
        "    \"\"\"Convert Tensors to HalfTensors\"\"\"\n",
        "    def __init__(self, use_half):\n",
        "      self.use_half = use_half\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            Tensor, use_half\n",
        "\n",
        "        Returns:\n",
        "            Half precision typecast tensor if use_half=True\n",
        "              else: do nothing\n",
        "        \"\"\"\n",
        "        if self.use_half:\n",
        "          img = img.half()\n",
        "\n",
        "        return img\n",
        "\n",
        "\n",
        "def get_dataloader(dataset=\"MNIST\", use_half=False, PRELOAD=False):\n",
        "  if dataset == 'MNIST':\n",
        "      train_set = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                            ToHalfTensor(use_half),\n",
        "                        ]))\n",
        "      test_set = torchvision.datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                            ToHalfTensor(use_half),\n",
        "                        ]))\n",
        "  elif dataset == 'EMNIST':\n",
        "    train_set = torchvision.datasets.EMNIST('./data', split=\"digits\", train=True, download=True,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                            ToHalfTensor(use_half),\n",
        "                        ]))\n",
        "    test_set = torchvision.datasets.EMNIST('./data', split=\"digits\", train=False, transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                            ToHalfTensor(use_half),\n",
        "                        ]))\n",
        "    \n",
        "  elif dataset == 'Cifar10':\n",
        "    transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            ToHalfTensor(use_half),\n",
        "        ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "        ToHalfTensor(use_half),\n",
        "    ])\n",
        "\n",
        "    train_set = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "    test_set = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "  \n",
        "  preloaded_train_loader = []\n",
        "  if PRELOAD:\n",
        "    # nothing fancy. Just preload into a list\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "      preloaded_train_loader.append((inputs, labels))\n",
        "    train_loader = preloaded_train_loader\n",
        "\n",
        "  return (train_loader, test_loader)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "# test function:\n",
        "def test(dataset, model, device, test_loader, criterion):\n",
        "  class_correct = list(0. for i in range(10))\n",
        "  class_total = list(0. for i in range(10))\n",
        "  if dataset in ['EMNIST', 'MNIST']:\n",
        "      classes = [str(i) for i in range(10)]\n",
        "  elif dataset == 'Cifar10':\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
        "               'horse', 'ship', 'truck')\n",
        "\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = model(data)\n",
        "          _, predicted = torch.max(output, 1)\n",
        "          c = (predicted == target).squeeze()\n",
        "\n",
        "          test_loss = criterion(output, target).item()\n",
        "          pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "          correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "          for image_index in range(test_batch_size):\n",
        "              label = target[image_index]\n",
        "              class_correct[label] += c[image_index].item()\n",
        "              class_total[label] += 1\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  for i in range(10):\n",
        "      logger.info('Accuracy of %5s : %2d %%' % (\n",
        "          classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "\n",
        "  logger.info('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))\n",
        "  \n",
        "  return 100.0 * correct/len(test_loader.dataset)\n",
        "\n",
        "# train method\n",
        "def train(model, optimizer, criterion, scaler, train_loader, use_amp, epoch=0):\n",
        "\n",
        "  for batch_idx, (inputs, labels) in enumerate(train_loader): # Iterating through the train loader\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()            # Reset the gradient in every iteration\n",
        "    with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs,labels) # Loss forward pass\n",
        "    scaler.scale(loss).backward()      # Loss backward pass\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()                    # Update all the parameters by the given learning rule\n",
        "    # optimizer.zero_grad()              # set_to_none=True here can modestly improve performance\n",
        "  \n",
        "    if batch_idx % 500 == 0:\n",
        "      logger.info('Train Epoch: {} [{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(inputs),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "  return loss.item()\n",
        "\n",
        "def run_experiment(MAX_EPOCHS=3):\n",
        "  epoch_list = [0]\n",
        "  loss_epoch_list = [-1]\n",
        "  epoch_train_time_list = [-1]\n",
        "  total_train_time_list = [-1]\n",
        "  lr_list = [-1]\n",
        "  test_acc_list = []\n",
        "\n",
        "  # get data\n",
        "  train_loader, test_loader = get_dataloader(dataset, use_half=use_half_all, PRELOAD=PRELOAD)\n",
        "  \n",
        "  if dataset in ['MNIST', 'EMNIST']:\n",
        "    model = Net().to(device)\n",
        "  elif dataset == 'Cifar10':\n",
        "    model = vgg11().to(device)\n",
        "  else:\n",
        "    logger.info(\"BAD DATASET!!!\")\n",
        "    exit()\n",
        "  \n",
        "  if use_half_all:\n",
        "    model.half()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  curr_lr = 0.01\n",
        "  optimizer = optim.SGD(model.parameters(), lr=curr_lr, momentum=0.9)\n",
        "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "  total_training_time = 0\n",
        "\n",
        "  # check accuracy before training\n",
        "  test_acc = test(dataset, model, device, test_loader, criterion)\n",
        "  test_acc_list.append(test_acc)\n",
        "\n",
        "  for epoch in range(1, MAX_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    last_epoch_loss = train(model, optimizer, criterion, scaler, train_loader, use_amp, epoch)\n",
        "    end_time = time.time()\n",
        "    epoch_training_time = end_time - start_time\n",
        "    total_training_time += epoch_training_time\n",
        "    epoch_list.append(epoch)\n",
        "    epoch_train_time_list.append(epoch_training_time)\n",
        "    total_train_time_list.append(total_training_time)\n",
        "    lr_list.append(curr_lr)\n",
        "    test_acc = test(dataset, model, device, test_loader, criterion)\n",
        "    test_acc_list.append(test_acc)\n",
        "    loss_epoch_list.append(last_epoch_loss)\n",
        "\n",
        "    # cut learning rate in half every 20 epochs\n",
        "    if epoch % 20 == 19:\n",
        "      curr_lr = 0.5 * curr_lr\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = curr_lr\n",
        "\n",
        "\n",
        "  # (OPTIONAL) Save trained model:\n",
        "  #PATH = './cifar_net.pt'\n",
        "  #torch.save(net.state_dict(), PATH)\n",
        "\n",
        "  # (OPTIONAL) Load saved model\n",
        "  #net.load_state_dict(torch.load(PATH))\n",
        "  #net.to(device)\n",
        "\n",
        "  results_df = pd.DataFrame({\"epoch\": epoch_list, \"training_loss\": loss_epoch_list, \"test_acc\": test_acc_list, \"epoch_train_time\": epoch_train_time_list, \"total_train_time\": total_train_time_list, \"lr\": lr_list, })\n",
        "  return results_df\n",
        "\n",
        "seed_experiment(42)\n",
        "use_half_all=False\n",
        "results_df = run_experiment(MAX_EPOCHS=3)\n",
        "results_df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeded everything with seed: 42\n",
            "using Tesla T4\n",
            "Seeded everything with seed: 42\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Accuracy of plane :  0 %\n",
            "INFO:root:Accuracy of   car :  0 %\n",
            "INFO:root:Accuracy of  bird :  0 %\n",
            "INFO:root:Accuracy of   cat :  0 %\n",
            "INFO:root:Accuracy of  deer :  0 %\n",
            "INFO:root:Accuracy of   dog :  0 %\n",
            "INFO:root:Accuracy of  frog :  0 %\n",
            "INFO:root:Accuracy of horse :  0 %\n",
            "INFO:root:Accuracy of  ship :  0 %\n",
            "INFO:root:Accuracy of truck :  0 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0007, Accuracy: 0/10000 (0%)\n",
            "\n",
            "INFO:root:Train Epoch: 1 [0 (0%)]\tLoss: 6.921206\n",
            "INFO:root:Train Epoch: 1 [32000 (64%)]\tLoss: 1.603750\n",
            "INFO:root:Accuracy of plane : 46 %\n",
            "INFO:root:Accuracy of   car : 71 %\n",
            "INFO:root:Accuracy of  bird : 41 %\n",
            "INFO:root:Accuracy of   cat :  1 %\n",
            "INFO:root:Accuracy of  deer :  0 %\n",
            "INFO:root:Accuracy of   dog : 66 %\n",
            "INFO:root:Accuracy of  frog :  9 %\n",
            "INFO:root:Accuracy of horse : 30 %\n",
            "INFO:root:Accuracy of  ship : 61 %\n",
            "INFO:root:Accuracy of truck : 43 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0002, Accuracy: 3714/10000 (37%)\n",
            "\n",
            "INFO:root:Train Epoch: 2 [0 (0%)]\tLoss: 1.908351\n",
            "INFO:root:Train Epoch: 2 [32000 (64%)]\tLoss: 1.428693\n",
            "INFO:root:Accuracy of plane : 62 %\n",
            "INFO:root:Accuracy of   car : 76 %\n",
            "INFO:root:Accuracy of  bird : 28 %\n",
            "INFO:root:Accuracy of   cat : 42 %\n",
            "INFO:root:Accuracy of  deer : 51 %\n",
            "INFO:root:Accuracy of   dog : 46 %\n",
            "INFO:root:Accuracy of  frog : 57 %\n",
            "INFO:root:Accuracy of horse : 69 %\n",
            "INFO:root:Accuracy of  ship : 60 %\n",
            "INFO:root:Accuracy of truck : 75 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0001, Accuracy: 5712/10000 (57%)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>epoch_train_time</th>\n",
              "      <th>total_train_time</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.873167</td>\n",
              "      <td>37.14</td>\n",
              "      <td>47.679572</td>\n",
              "      <td>47.679572</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.332349</td>\n",
              "      <td>57.12</td>\n",
              "      <td>47.487087</td>\n",
              "      <td>95.166659</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  training_loss  test_acc  epoch_train_time  total_train_time    lr\n",
              "0      0      -1.000000      0.00         -1.000000         -1.000000 -1.00\n",
              "1      1       1.873167     37.14         47.679572         47.679572  0.01\n",
              "2      2       1.332349     57.12         47.487087         95.166659  0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbLhKZpkdW3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "dcf60ab5-015e-494c-ae83-88e8595cd459"
      },
      "source": [
        "seed_experiment(42)\n",
        "use_half_all=True\n",
        "results_df = run_experiment(MAX_EPOCHS=3)\n",
        "use_half_all=False\n",
        "results_df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeded everything with seed: 42\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Accuracy of plane :  0 %\n",
            "INFO:root:Accuracy of   car :  0 %\n",
            "INFO:root:Accuracy of  bird :  0 %\n",
            "INFO:root:Accuracy of   cat :  0 %\n",
            "INFO:root:Accuracy of  deer :  0 %\n",
            "INFO:root:Accuracy of   dog :  0 %\n",
            "INFO:root:Accuracy of  frog :  0 %\n",
            "INFO:root:Accuracy of horse :  0 %\n",
            "INFO:root:Accuracy of  ship :  0 %\n",
            "INFO:root:Accuracy of truck :  0 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0007, Accuracy: 0/10000 (0%)\n",
            "\n",
            "INFO:root:Train Epoch: 1 [0 (0%)]\tLoss: 6.921875\n",
            "INFO:root:Train Epoch: 1 [32000 (64%)]\tLoss: 1.545898\n",
            "INFO:root:Accuracy of plane : 23 %\n",
            "INFO:root:Accuracy of   car : 87 %\n",
            "INFO:root:Accuracy of  bird : 21 %\n",
            "INFO:root:Accuracy of   cat :  5 %\n",
            "INFO:root:Accuracy of  deer :  0 %\n",
            "INFO:root:Accuracy of   dog : 64 %\n",
            "INFO:root:Accuracy of  frog : 67 %\n",
            "INFO:root:Accuracy of horse : 44 %\n",
            "INFO:root:Accuracy of  ship : 59 %\n",
            "INFO:root:Accuracy of truck : 43 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0002, Accuracy: 4161/10000 (42%)\n",
            "\n",
            "INFO:root:Train Epoch: 2 [0 (0%)]\tLoss: 1.933594\n",
            "INFO:root:Train Epoch: 2 [32000 (64%)]\tLoss: 1.340820\n",
            "INFO:root:Accuracy of plane : 75 %\n",
            "INFO:root:Accuracy of   car : 73 %\n",
            "INFO:root:Accuracy of  bird : 30 %\n",
            "INFO:root:Accuracy of   cat : 41 %\n",
            "INFO:root:Accuracy of  deer : 53 %\n",
            "INFO:root:Accuracy of   dog : 34 %\n",
            "INFO:root:Accuracy of  frog : 55 %\n",
            "INFO:root:Accuracy of horse : 64 %\n",
            "INFO:root:Accuracy of  ship : 59 %\n",
            "INFO:root:Accuracy of truck : 78 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0001, Accuracy: 5653/10000 (57%)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>epoch_train_time</th>\n",
              "      <th>total_train_time</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.987305</td>\n",
              "      <td>41.61</td>\n",
              "      <td>45.613671</td>\n",
              "      <td>45.613671</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.456055</td>\n",
              "      <td>56.53</td>\n",
              "      <td>45.514052</td>\n",
              "      <td>91.127722</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  training_loss  test_acc  epoch_train_time  total_train_time    lr\n",
              "0      0      -1.000000      0.00         -1.000000         -1.000000 -1.00\n",
              "1      1       1.987305     41.61         45.613671         45.613671  0.01\n",
              "2      2       1.456055     56.53         45.514052         91.127722  0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1X7XnJgdj5s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzfGAV3duOsh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "af67e559-612e-4a08-b563-e29a7d275468"
      },
      "source": [
        "seed_experiment(42)\n",
        "use_amp=True\n",
        "results_df = run_experiment(MAX_EPOCHS=3)\n",
        "use_amp=False\n",
        "results_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeded everything with seed: 42\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Accuracy of plane :  0 %\n",
            "INFO:root:Accuracy of   car :  0 %\n",
            "INFO:root:Accuracy of  bird :  0 %\n",
            "INFO:root:Accuracy of   cat :  0 %\n",
            "INFO:root:Accuracy of  deer :  0 %\n",
            "INFO:root:Accuracy of   dog :  0 %\n",
            "INFO:root:Accuracy of  frog :  0 %\n",
            "INFO:root:Accuracy of horse :  0 %\n",
            "INFO:root:Accuracy of  ship :  0 %\n",
            "INFO:root:Accuracy of truck :  0 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0007, Accuracy: 0/10000 (0%)\n",
            "\n",
            "INFO:root:Train Epoch: 1 [0 (0%)]\tLoss: 6.921195\n",
            "INFO:root:Train Epoch: 1 [32000 (64%)]\tLoss: 1.663948\n",
            "INFO:root:Accuracy of plane : 47 %\n",
            "INFO:root:Accuracy of   car : 85 %\n",
            "INFO:root:Accuracy of  bird : 33 %\n",
            "INFO:root:Accuracy of   cat :  1 %\n",
            "INFO:root:Accuracy of  deer :  0 %\n",
            "INFO:root:Accuracy of   dog : 69 %\n",
            "INFO:root:Accuracy of  frog : 16 %\n",
            "INFO:root:Accuracy of horse : 44 %\n",
            "INFO:root:Accuracy of  ship : 48 %\n",
            "INFO:root:Accuracy of truck : 22 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0002, Accuracy: 3694/10000 (37%)\n",
            "\n",
            "INFO:root:Train Epoch: 2 [0 (0%)]\tLoss: 1.901588\n",
            "INFO:root:Train Epoch: 2 [32000 (64%)]\tLoss: 1.487112\n",
            "INFO:root:Accuracy of plane : 60 %\n",
            "INFO:root:Accuracy of   car : 71 %\n",
            "INFO:root:Accuracy of  bird : 36 %\n",
            "INFO:root:Accuracy of   cat : 51 %\n",
            "INFO:root:Accuracy of  deer : 41 %\n",
            "INFO:root:Accuracy of   dog : 16 %\n",
            "INFO:root:Accuracy of  frog : 49 %\n",
            "INFO:root:Accuracy of horse : 69 %\n",
            "INFO:root:Accuracy of  ship : 66 %\n",
            "INFO:root:Accuracy of truck : 78 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0001, Accuracy: 5405/10000 (54%)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>epoch_train_time</th>\n",
              "      <th>total_train_time</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.884535</td>\n",
              "      <td>36.94</td>\n",
              "      <td>67.278944</td>\n",
              "      <td>67.278944</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.513227</td>\n",
              "      <td>54.05</td>\n",
              "      <td>67.359797</td>\n",
              "      <td>134.638741</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  training_loss  test_acc  epoch_train_time  total_train_time    lr\n",
              "0      0      -1.000000      0.00         -1.000000         -1.000000 -1.00\n",
              "1      1       1.884535     36.94         67.278944         67.278944  0.01\n",
              "2      2       1.513227     54.05         67.359797        134.638741  0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzxYDPIBsswc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}