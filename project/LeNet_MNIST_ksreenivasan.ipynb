{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet-MNIST_ksreenivasan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamikazekartik/cs744_assignments/blob/master/project/LeNet_MNIST_ksreenivasan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrhNaWmyAxP-"
      },
      "source": [
        "Baseline performance and timings for training LeNet on MNIST/EMNIST.\n",
        "\n",
        "Before running the notebook, go to Runtime -> Change Runtime Type in the menu and set Hardware Accelerator to GPU. **Make sure you change it back** when finished to avoid being penalized by Colab.\n",
        "\n",
        "You can use the dataset variable to decide if to run on MNIST or EMNIST (EMNIST will be slightly slower since the training data is significantly larger)\n",
        "\n",
        "Each cell runs with different precision settings\n",
        "\n",
        "Strange behavior right now:\n",
        "1. Full precision is the fastest.\n",
        "2. Half precision is about half a second slower per epoch.\n",
        "3. AMP is still slower by another whole second.\n",
        "\n",
        "Code is based on [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9d5Kq0U8iwo",
        "outputId": "2cc0753b-391e-4926-ebde-670099ad76df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "import time\n",
        "import os, random\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "def seed_experiment(seed=0):\n",
        "    # seed = 1234\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    #TODO: Do we need deterministic in cudnn ? Double check\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(\"Seeded everything with seed: {}\".format(seed))\n",
        "\n",
        "# seed experiment\n",
        "seed_experiment(42)\n",
        "\n",
        "# Options:\n",
        "use_amp = False\n",
        "use_half_all = True\n",
        "use_half_conv = False\n",
        "use_half_lin = False\n",
        "dataset = 'MNIST'\n",
        "\n",
        "# Make sure we're using a GPU, and report what GPU it is.\n",
        "# (Otherwise this would run **forever**)\n",
        "if torch.cuda.is_available():\n",
        "  print(\"using \"+torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print('No GPU available (enable it?), quitting.')\n",
        "  exit()\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# Set up dataset:\n",
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "\n",
        "if dataset == 'MNIST':\n",
        "    train_set = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ]))\n",
        "    test_set = torchvision.datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ]))\n",
        "elif dataset == 'EMNIST':\n",
        "  train_set = torchvision.datasets.EMNIST('./data', split=\"digits\", train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ]))\n",
        "  test_set = torchvision.datasets.EMNIST('./data', split=\"digits\", train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ]))\n",
        "\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, shuffle=False, num_workers=2)\n",
        "classes = ('0','1','2','3','4','5','6','7','8','9')\n",
        "\n",
        "# Set up and load LeNet model:\n",
        "# this version seems to be significantly slower when we use half precision\n",
        "# TODO: perhaps because of all the conversions?\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    global use_half_all, use_half_conv, use_half_lin\n",
        "    super(LeNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5).half() if use_half_all or use_half_conv else nn.Conv2d(1, 6, 5)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5).half() if use_half_all or use_half_conv else nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(256, 120).half() if use_half_all or use_half_lin else nn.Linear(256, 120)\n",
        "    self.fc2 = nn.Linear(120, 84).half() if use_half_all or use_half_lin else nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10).half() if use_half_all or use_half_lin else nn.Linear(84, 10)\n",
        "    self.relu1 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(2).half() if use_half_all else nn.MaxPool2d(2)\n",
        "    self.relu2 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(2).half() if use_half_all else nn.MaxPool2d(2)\n",
        "    self.relu3 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "    self.relu4 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "    self.relu5 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    global use_half_all, use_half_conv, use_half_lin\n",
        "    y = self.conv1(x.half()).float() if use_half_all or use_half_conv else self.conv1(x)\n",
        "    y = self.relu1(y.half()).float() if use_half_all else self.relu1(y)\n",
        "    y = self.pool1(y.half()).float() if use_half_all else self.pool1(y)\n",
        "    y = self.conv2(y.half()).float() if use_half_all or use_half_conv else self.conv2(y)\n",
        "    y = self.relu2(y.half()).float() if use_half_all else self.relu2(y)\n",
        "    y = self.pool2(y.half()).float() if use_half_all else self.pool1(y)\n",
        "    y = y.view(y.shape[0], -1)\n",
        "    y = self.fc1(y.half()).float() if use_half_all or use_half_lin else self.fc1(y)\n",
        "    y = self.relu3(y.half()).float() if use_half_all else self.relu3(y)\n",
        "    y = self.fc2(y.half()).float() if use_half_all or use_half_lin else self.fc2(y)\n",
        "    y = self.relu4(y.half()).float() if use_half_all else self.relu4(y)\n",
        "    y = self.fc3(y.half()).float() if use_half_all or use_half_lin else self.fc3(y)\n",
        "    y = self.relu5(y.half()).float() if use_half_all else self.relu5(y)\n",
        "    return y\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "# test function:\n",
        "def test(dataset, model, device, test_loader, criterion):\n",
        "  class_correct = list(0. for i in range(10))\n",
        "  class_total = list(0. for i in range(10))\n",
        "  if dataset in [\"EMNIST\", \"MNIST\"]:\n",
        "      classes = [str(i) for i in range(10)]\n",
        "\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          if use_half_all:\n",
        "            data = data.half()\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = model(data)\n",
        "          _, predicted = torch.max(output, 1)\n",
        "          c = (predicted == target).squeeze()\n",
        "\n",
        "          test_loss = criterion(output, target).item()\n",
        "          pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "          correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "          for image_index in range(test_batch_size):\n",
        "              label = target[image_index]\n",
        "              class_correct[label] += c[image_index].item()\n",
        "              class_total[label] += 1\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  for i in range(10):\n",
        "      logger.info('Accuracy of %5s : %2d %%' % (\n",
        "          classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "\n",
        "  logger.info('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))\n",
        "  \n",
        "  return 100.0 * correct/len(test_loader.dataset)\n",
        "\n",
        "# train method\n",
        "def train(model, optimizer, scaler, train_loader, use_amp, epoch=0):\n",
        "\n",
        "  for batch_idx, (inputs, labels) in enumerate(train_loader): # Iterating through the train loader\n",
        "    if use_half_all:\n",
        "      inputs = inputs.half()\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()            # Reset the gradient in every iteration\n",
        "    with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs,labels) # Loss forward pass\n",
        "    scaler.scale(loss).backward()      # Loss backward pass\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()                    # Update all the parameters by the given learning rule\n",
        "    # optimizer.zero_grad()              # set_to_none=True here can modestly improve performance\n",
        "  \n",
        "    if batch_idx % 500 == 0:\n",
        "      logger.info('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(inputs), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "  return loss.item()\n",
        "\n",
        "def run_experiment(MAX_EPOCHS=3):\n",
        "  epoch_list = [0]\n",
        "  loss_epoch_list = [-1]\n",
        "  epoch_train_time_list = [-1]\n",
        "  total_train_time_list = [-1]\n",
        "  lr_list = [-1]\n",
        "  test_acc_list = []\n",
        "\n",
        "  model = Net().to(device)\n",
        "  if use_half_all:\n",
        "    model.half()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  curr_lr = 0.01\n",
        "  optimizer = optim.SGD(model.parameters(), lr=curr_lr, momentum=0.9)\n",
        "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "  total_training_time = 0\n",
        "\n",
        "  # check accuracy before training\n",
        "  test_acc = test(dataset, model, device, test_loader, criterion)\n",
        "  test_acc_list.append(test_acc)\n",
        "\n",
        "  for epoch in range(1, MAX_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    last_epoch_loss = train(model, optimizer, scaler, train_loader, use_amp, epoch)\n",
        "    end_time = time.time()\n",
        "    epoch_training_time = end_time - start_time\n",
        "    total_training_time += epoch_training_time\n",
        "    epoch_list.append(epoch)\n",
        "    epoch_train_time_list.append(epoch_training_time)\n",
        "    total_train_time_list.append(total_training_time)\n",
        "    lr_list.append(curr_lr)\n",
        "    test_acc = test(\"EMNIST\", model, device, test_loader, criterion)\n",
        "    test_acc_list.append(test_acc)\n",
        "    loss_epoch_list.append(last_epoch_loss)\n",
        "\n",
        "    # cut learning rate in half every 20 epochs\n",
        "    if epoch % 20 == 19:\n",
        "      curr_lr = 0.5 * curr_lr\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = curr_lr\n",
        "\n",
        "\n",
        "  # (OPTIONAL) Save trained model:\n",
        "  #PATH = './cifar_net.pt'\n",
        "  #torch.save(net.state_dict(), PATH)\n",
        "\n",
        "  # (OPTIONAL) Load saved model\n",
        "  #net.load_state_dict(torch.load(PATH))\n",
        "  #net.to(device)\n",
        "\n",
        "  results_df = pd.DataFrame({\"epoch\": epoch_list, \"training_loss\": loss_epoch_list, \"test_acc\": test_acc_list, \"epoch_train_time\": epoch_train_time_list, \"total_train_time\": total_train_time_list, \"lr\": lr_list, })\n",
        "  return results_df\n",
        "\n",
        "seed_experiment(42)\n",
        "use_half_all=False\n",
        "results_df = run_experiment(MAX_EPOCHS=3)\n",
        "results_df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeded everything with seed: 42\n",
            "using Tesla T4\n",
            "Seeded everything with seed: 42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Accuracy of     0 : 90 %\n",
            "INFO:root:Accuracy of     1 :  0 %\n",
            "INFO:root:Accuracy of     2 :  0 %\n",
            "INFO:root:Accuracy of     3 : 21 %\n",
            "INFO:root:Accuracy of     4 :  0 %\n",
            "INFO:root:Accuracy of     5 :  0 %\n",
            "INFO:root:Accuracy of     6 :  0 %\n",
            "INFO:root:Accuracy of     7 :  0 %\n",
            "INFO:root:Accuracy of     8 :  0 %\n",
            "INFO:root:Accuracy of     9 :  0 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0002, Accuracy: 1102/10000 (11%)\n",
            "\n",
            "INFO:root:Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300759\n",
            "INFO:root:Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.207401\n",
            "INFO:root:Accuracy of     0 : 99 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 98 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 95 %\n",
            "INFO:root:Accuracy of     5 : 96 %\n",
            "INFO:root:Accuracy of     6 : 97 %\n",
            "INFO:root:Accuracy of     7 : 96 %\n",
            "INFO:root:Accuracy of     8 : 97 %\n",
            "INFO:root:Accuracy of     9 : 97 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9777/10000 (98%)\n",
            "\n",
            "INFO:root:Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.076952\n",
            "INFO:root:Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.003811\n",
            "INFO:root:Accuracy of     0 : 99 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 98 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 99 %\n",
            "INFO:root:Accuracy of     5 : 98 %\n",
            "INFO:root:Accuracy of     6 : 98 %\n",
            "INFO:root:Accuracy of     7 : 96 %\n",
            "INFO:root:Accuracy of     8 : 98 %\n",
            "INFO:root:Accuracy of     9 : 96 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9839/10000 (98%)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>epoch_train_time</th>\n",
              "      <th>total_train_time</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>11.02</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.187244</td>\n",
              "      <td>97.77</td>\n",
              "      <td>11.769855</td>\n",
              "      <td>11.769855</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.002467</td>\n",
              "      <td>98.39</td>\n",
              "      <td>11.866599</td>\n",
              "      <td>23.636454</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  training_loss  test_acc  epoch_train_time  total_train_time    lr\n",
              "0      0      -1.000000     11.02         -1.000000         -1.000000 -1.00\n",
              "1      1       0.187244     97.77         11.769855         11.769855  0.01\n",
              "2      2       0.002467     98.39         11.866599         23.636454  0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbLhKZpkdW3E",
        "outputId": "93e14534-625f-4b05-cc09-74bb495024f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "seed_experiment(42)\n",
        "use_half_all=True\n",
        "results_df = run_experiment(MAX_EPOCHS=3)\n",
        "results_df\n",
        "use_half_all=False"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeded everything with seed: 42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Accuracy of     0 : 90 %\n",
            "INFO:root:Accuracy of     1 :  0 %\n",
            "INFO:root:Accuracy of     2 :  0 %\n",
            "INFO:root:Accuracy of     3 : 20 %\n",
            "INFO:root:Accuracy of     4 :  0 %\n",
            "INFO:root:Accuracy of     5 :  0 %\n",
            "INFO:root:Accuracy of     6 :  0 %\n",
            "INFO:root:Accuracy of     7 :  0 %\n",
            "INFO:root:Accuracy of     8 :  0 %\n",
            "INFO:root:Accuracy of     9 :  0 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0002, Accuracy: 1099/10000 (11%)\n",
            "\n",
            "INFO:root:Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300781\n",
            "INFO:root:Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.206299\n",
            "INFO:root:Accuracy of     0 : 99 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 98 %\n",
            "INFO:root:Accuracy of     3 : 97 %\n",
            "INFO:root:Accuracy of     4 : 96 %\n",
            "INFO:root:Accuracy of     5 : 97 %\n",
            "INFO:root:Accuracy of     6 : 98 %\n",
            "INFO:root:Accuracy of     7 : 97 %\n",
            "INFO:root:Accuracy of     8 : 97 %\n",
            "INFO:root:Accuracy of     9 : 97 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9795/10000 (98%)\n",
            "\n",
            "INFO:root:Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.115356\n",
            "INFO:root:Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.005417\n",
            "INFO:root:Accuracy of     0 : 99 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 98 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 99 %\n",
            "INFO:root:Accuracy of     5 : 98 %\n",
            "INFO:root:Accuracy of     6 : 98 %\n",
            "INFO:root:Accuracy of     7 : 97 %\n",
            "INFO:root:Accuracy of     8 : 98 %\n",
            "INFO:root:Accuracy of     9 : 96 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9845/10000 (98%)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>epoch_train_time</th>\n",
              "      <th>total_train_time</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>10.99</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.153076</td>\n",
              "      <td>97.95</td>\n",
              "      <td>12.092274</td>\n",
              "      <td>12.092274</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.001544</td>\n",
              "      <td>98.45</td>\n",
              "      <td>12.070343</td>\n",
              "      <td>24.162617</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  training_loss  test_acc  epoch_train_time  total_train_time    lr\n",
              "0      0      -1.000000     10.99         -1.000000         -1.000000 -1.00\n",
              "1      1       0.153076     97.95         12.092274         12.092274  0.01\n",
              "2      2       0.001544     98.45         12.070343         24.162617  0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1X7XnJgdj5s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzfGAV3duOsh",
        "outputId": "bb8669a3-e581-4d37-f6e5-5daf6dd5875b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "seed_experiment(42)\n",
        "use_amp=True\n",
        "results_df = run_experiment(MAX_EPOCHS=3)\n",
        "results_df\n",
        "use_amp=False"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeded everything with seed: 42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Accuracy of     0 : 90 %\n",
            "INFO:root:Accuracy of     1 :  0 %\n",
            "INFO:root:Accuracy of     2 :  0 %\n",
            "INFO:root:Accuracy of     3 : 21 %\n",
            "INFO:root:Accuracy of     4 :  0 %\n",
            "INFO:root:Accuracy of     5 :  0 %\n",
            "INFO:root:Accuracy of     6 :  0 %\n",
            "INFO:root:Accuracy of     7 :  0 %\n",
            "INFO:root:Accuracy of     8 :  0 %\n",
            "INFO:root:Accuracy of     9 :  0 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0002, Accuracy: 1102/10000 (11%)\n",
            "\n",
            "INFO:root:Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300760\n",
            "INFO:root:Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.207569\n",
            "INFO:root:Accuracy of     0 : 99 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 98 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 96 %\n",
            "INFO:root:Accuracy of     5 : 97 %\n",
            "INFO:root:Accuracy of     6 : 96 %\n",
            "INFO:root:Accuracy of     7 : 96 %\n",
            "INFO:root:Accuracy of     8 : 98 %\n",
            "INFO:root:Accuracy of     9 : 97 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9791/10000 (98%)\n",
            "\n",
            "INFO:root:Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.064947\n",
            "INFO:root:Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.009189\n",
            "INFO:root:Accuracy of     0 : 99 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 98 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 98 %\n",
            "INFO:root:Accuracy of     5 : 98 %\n",
            "INFO:root:Accuracy of     6 : 97 %\n",
            "INFO:root:Accuracy of     7 : 95 %\n",
            "INFO:root:Accuracy of     8 : 98 %\n",
            "INFO:root:Accuracy of     9 : 97 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9828/10000 (98%)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>epoch_train_time</th>\n",
              "      <th>total_train_time</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>11.02</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.159181</td>\n",
              "      <td>97.91</td>\n",
              "      <td>13.515776</td>\n",
              "      <td>13.515776</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.003910</td>\n",
              "      <td>98.28</td>\n",
              "      <td>13.584439</td>\n",
              "      <td>27.100215</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  training_loss  test_acc  epoch_train_time  total_train_time    lr\n",
              "0      0      -1.000000     11.02         -1.000000         -1.000000 -1.00\n",
              "1      1       0.159181     97.91         13.515776         13.515776  0.01\n",
              "2      2       0.003910     98.28         13.584439         27.100215  0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR6BKzo5uOzz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1iqTSbiuO2s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOrOLoH6uO82"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}