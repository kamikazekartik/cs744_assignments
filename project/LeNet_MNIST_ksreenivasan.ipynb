{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet-MNIST_ksreenivasan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamikazekartik/cs744_assignments/blob/master/project/LeNet_MNIST_ksreenivasan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrhNaWmyAxP-"
      },
      "source": [
        "Baseline performance and timings for training LeNet on MNIST/EMNIST.\n",
        "\n",
        "Before running the notebook, go to Runtime -> Change Runtime Type in the menu and set Hardware Accelerator to GPU. **Make sure you change it back** when finished to avoid being penalized by Colab.\n",
        "\n",
        "You can use the dataset variable to decide if to run on MNIST or EMNIST (EMNIST will be slightly slower since the training data is significantly larger)\n",
        "\n",
        "Each cell runs with different precision settings\n",
        "\n",
        "Strange behavior right now:\n",
        "1. Full precision is the fastest.\n",
        "2. Half precision is about half a second slower per epoch.\n",
        "3. AMP is still slower by another whole second.\n",
        "\n",
        "Code is based on [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9d5Kq0U8iwo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "a89647cb-bfee-4fa8-b11a-edc346592e0f"
      },
      "source": [
        "import time\n",
        "import os, random\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "def seed_experiment(seed=0):\n",
        "    # seed = 1234\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    # TODO: Do we need deterministic in cudnn ? Double check\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(\"Seeded everything with seed: {}\".format(seed))\n",
        "\n",
        "# seed experiment\n",
        "seed_experiment(42)\n",
        "\n",
        "# Options:\n",
        "use_amp = False\n",
        "use_half_all = True\n",
        "use_half_conv = False\n",
        "use_half_lin = False\n",
        "dataset = 'MNIST'\n",
        "PRELOAD = True # decides if we should use pytorch's dataloader or just preload into a python list\n",
        "\n",
        "# Make sure we're using a GPU, and report what GPU it is.\n",
        "# (Otherwise this would run **forever**)\n",
        "if torch.cuda.is_available():\n",
        "  print(\"using \"+torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print('No GPU available (enable it?), quitting.')\n",
        "  exit()\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# Set up dataset:\n",
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "\n",
        "class ToHalfTensor(object):\n",
        "    \"\"\"Convert Tensors to HalfTensors\"\"\"\n",
        "    def __init__(self, use_half):\n",
        "      self.use_half = use_half\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            Tensor, use_half\n",
        "\n",
        "        Returns:\n",
        "            Half precision typecast tensor if use_half=True\n",
        "              else: do nothing\n",
        "        \"\"\"\n",
        "        if self.use_half:\n",
        "          img = img.half()\n",
        "\n",
        "        return img\n",
        "\n",
        "\n",
        "def get_dataloader(dataset=\"MNIST\", use_half=False, PRELOAD=False):\n",
        "  if dataset == 'MNIST':\n",
        "      train_set = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                            ToHalfTensor(use_half),\n",
        "                        ]))\n",
        "      test_set = torchvision.datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                            ToHalfTensor(use_half),\n",
        "                        ]))\n",
        "  elif dataset == 'EMNIST':\n",
        "    train_set = torchvision.datasets.EMNIST('./data', split=\"digits\", train=True, download=True,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                            ToHalfTensor(use_half),\n",
        "                        ]))\n",
        "    test_set = torchvision.datasets.EMNIST('./data', split=\"digits\", train=False, transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                            ToHalfTensor(use_half),\n",
        "                        ]))\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, shuffle=False, num_workers=2)\n",
        "  classes = ('0','1','2','3','4','5','6','7','8','9')\n",
        "  \n",
        "  preloaded_train_loader = []\n",
        "  if PRELOAD:\n",
        "    # nothing fancy. Just preload into a list\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "      preloaded_train_loader.append((inputs, labels))\n",
        "    train_loader = preloaded_train_loader\n",
        "\n",
        "  return (train_loader, test_loader)\n",
        "\n",
        "\n",
        "\n",
        "# Set up and load LeNet model:\n",
        "# this version seems to be significantly slower when we use half precision\n",
        "# TODO: perhaps because of all the conversions?\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    global use_half_all, use_half_conv, use_half_lin\n",
        "    super(LeNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5).half() if use_half_all or use_half_conv else nn.Conv2d(1, 6, 5)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5).half() if use_half_all or use_half_conv else nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(256, 120).half() if use_half_all or use_half_lin else nn.Linear(256, 120)\n",
        "    self.fc2 = nn.Linear(120, 84).half() if use_half_all or use_half_lin else nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10).half() if use_half_all or use_half_lin else nn.Linear(84, 10)\n",
        "    self.relu1 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(2).half() if use_half_all else nn.MaxPool2d(2)\n",
        "    self.relu2 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(2).half() if use_half_all else nn.MaxPool2d(2)\n",
        "    self.relu3 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "    self.relu4 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "    self.relu5 = nn.ReLU().half() if use_half_all else nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    global use_half_all, use_half_conv, use_half_lin\n",
        "    y = self.conv1(x.half()).float() if use_half_all or use_half_conv else self.conv1(x)\n",
        "    y = self.relu1(y.half()).float() if use_half_all else self.relu1(y)\n",
        "    y = self.pool1(y.half()).float() if use_half_all else self.pool1(y)\n",
        "    y = self.conv2(y.half()).float() if use_half_all or use_half_conv else self.conv2(y)\n",
        "    y = self.relu2(y.half()).float() if use_half_all else self.relu2(y)\n",
        "    y = self.pool2(y.half()).float() if use_half_all else self.pool1(y)\n",
        "    y = y.view(y.shape[0], -1)\n",
        "    y = self.fc1(y.half()).float() if use_half_all or use_half_lin else self.fc1(y)\n",
        "    y = self.relu3(y.half()).float() if use_half_all else self.relu3(y)\n",
        "    y = self.fc2(y.half()).float() if use_half_all or use_half_lin else self.fc2(y)\n",
        "    y = self.relu4(y.half()).float() if use_half_all else self.relu4(y)\n",
        "    y = self.fc3(y.half()).float() if use_half_all or use_half_lin else self.fc3(y)\n",
        "    y = self.relu5(y.half()).float() if use_half_all else self.relu5(y)\n",
        "    return y\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "# test function:\n",
        "def test(dataset, model, device, test_loader, criterion):\n",
        "  class_correct = list(0. for i in range(10))\n",
        "  class_total = list(0. for i in range(10))\n",
        "  if dataset in [\"EMNIST\", \"MNIST\"]:\n",
        "      classes = [str(i) for i in range(10)]\n",
        "\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = model(data)\n",
        "          _, predicted = torch.max(output, 1)\n",
        "          c = (predicted == target).squeeze()\n",
        "\n",
        "          test_loss = criterion(output, target).item()\n",
        "          pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "          correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "          for image_index in range(test_batch_size):\n",
        "              label = target[image_index]\n",
        "              class_correct[label] += c[image_index].item()\n",
        "              class_total[label] += 1\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  for i in range(10):\n",
        "      logger.info('Accuracy of %5s : %2d %%' % (\n",
        "          classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "\n",
        "  logger.info('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))\n",
        "  \n",
        "  return 100.0 * correct/len(test_loader.dataset)\n",
        "\n",
        "# train method\n",
        "def train(model, optimizer, criterion, scaler, train_loader, use_amp, epoch=0):\n",
        "\n",
        "  for batch_idx, (inputs, labels) in enumerate(train_loader): # Iterating through the train loader\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()            # Reset the gradient in every iteration\n",
        "    with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs,labels) # Loss forward pass\n",
        "    scaler.scale(loss).backward()      # Loss backward pass\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()                    # Update all the parameters by the given learning rule\n",
        "    # optimizer.zero_grad()              # set_to_none=True here can modestly improve performance\n",
        "  \n",
        "    if batch_idx % 500 == 0:\n",
        "      logger.info('Train Epoch: {} [{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(inputs),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "  return loss.item()\n",
        "\n",
        "def run_experiment(MAX_EPOCHS=3):\n",
        "  epoch_list = [0]\n",
        "  loss_epoch_list = [-1]\n",
        "  epoch_train_time_list = [-1]\n",
        "  total_train_time_list = [-1]\n",
        "  lr_list = [-1]\n",
        "  test_acc_list = []\n",
        "\n",
        "  # get data\n",
        "  train_loader, test_loader = get_dataloader(dataset, use_half=use_half_all, PRELOAD=PRELOAD)\n",
        "  \n",
        "  model = Net().to(device)\n",
        "  if use_half_all:\n",
        "    model.half()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  curr_lr = 0.01\n",
        "  optimizer = optim.SGD(model.parameters(), lr=curr_lr, momentum=0.9)\n",
        "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "  total_training_time = 0\n",
        "\n",
        "  # check accuracy before training\n",
        "  test_acc = test(dataset, model, device, test_loader, criterion)\n",
        "  test_acc_list.append(test_acc)\n",
        "\n",
        "  for epoch in range(1, MAX_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    last_epoch_loss = train(model, optimizer, criterion, scaler, train_loader, use_amp, epoch)\n",
        "    end_time = time.time()\n",
        "    epoch_training_time = end_time - start_time\n",
        "    total_training_time += epoch_training_time\n",
        "    epoch_list.append(epoch)\n",
        "    epoch_train_time_list.append(epoch_training_time)\n",
        "    total_train_time_list.append(total_training_time)\n",
        "    lr_list.append(curr_lr)\n",
        "    test_acc = test(\"EMNIST\", model, device, test_loader, criterion)\n",
        "    test_acc_list.append(test_acc)\n",
        "    loss_epoch_list.append(last_epoch_loss)\n",
        "\n",
        "    # cut learning rate in half every 20 epochs\n",
        "    if epoch % 20 == 19:\n",
        "      curr_lr = 0.5 * curr_lr\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = curr_lr\n",
        "\n",
        "\n",
        "  # (OPTIONAL) Save trained model:\n",
        "  #PATH = './cifar_net.pt'\n",
        "  #torch.save(net.state_dict(), PATH)\n",
        "\n",
        "  # (OPTIONAL) Load saved model\n",
        "  #net.load_state_dict(torch.load(PATH))\n",
        "  #net.to(device)\n",
        "\n",
        "  results_df = pd.DataFrame({\"epoch\": epoch_list, \"training_loss\": loss_epoch_list, \"test_acc\": test_acc_list, \"epoch_train_time\": epoch_train_time_list, \"total_train_time\": total_train_time_list, \"lr\": lr_list, })\n",
        "  return results_df\n",
        "\n",
        "seed_experiment(42)\n",
        "use_half_all=False\n",
        "results_df = run_experiment(MAX_EPOCHS=3)\n",
        "results_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeded everything with seed: 42\n",
            "using Tesla T4\n",
            "Seeded everything with seed: 42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Accuracy of     0 : 94 %\n",
            "INFO:root:Accuracy of     1 :  0 %\n",
            "INFO:root:Accuracy of     2 :  0 %\n",
            "INFO:root:Accuracy of     3 :  0 %\n",
            "INFO:root:Accuracy of     4 :  0 %\n",
            "INFO:root:Accuracy of     5 :  0 %\n",
            "INFO:root:Accuracy of     6 :  9 %\n",
            "INFO:root:Accuracy of     7 :  0 %\n",
            "INFO:root:Accuracy of     8 :  0 %\n",
            "INFO:root:Accuracy of     9 :  0 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0002, Accuracy: 1020/10000 (10%)\n",
            "\n",
            "INFO:root:Train Epoch: 1 [0 (0%)]\tLoss: 2.296603\n",
            "INFO:root:Train Epoch: 1 [32000 (53%)]\tLoss: 0.088716\n",
            "INFO:root:Accuracy of     0 : 98 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 98 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 99 %\n",
            "INFO:root:Accuracy of     5 : 96 %\n",
            "INFO:root:Accuracy of     6 : 98 %\n",
            "INFO:root:Accuracy of     7 : 96 %\n",
            "INFO:root:Accuracy of     8 : 97 %\n",
            "INFO:root:Accuracy of     9 : 95 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "INFO:root:Train Epoch: 2 [0 (0%)]\tLoss: 0.019881\n",
            "INFO:root:Train Epoch: 2 [32000 (53%)]\tLoss: 0.059565\n",
            "INFO:root:Accuracy of     0 : 99 %\n",
            "INFO:root:Accuracy of     1 : 98 %\n",
            "INFO:root:Accuracy of     2 : 99 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 98 %\n",
            "INFO:root:Accuracy of     5 : 98 %\n",
            "INFO:root:Accuracy of     6 : 98 %\n",
            "INFO:root:Accuracy of     7 : 97 %\n",
            "INFO:root:Accuracy of     8 : 98 %\n",
            "INFO:root:Accuracy of     9 : 98 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9848/10000 (98%)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>epoch_train_time</th>\n",
              "      <th>total_train_time</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>10.20</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.049105</td>\n",
              "      <td>98.00</td>\n",
              "      <td>2.473950</td>\n",
              "      <td>2.473950</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.039668</td>\n",
              "      <td>98.48</td>\n",
              "      <td>2.252508</td>\n",
              "      <td>4.726458</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  training_loss  test_acc  epoch_train_time  total_train_time    lr\n",
              "0      0      -1.000000     10.20         -1.000000         -1.000000 -1.00\n",
              "1      1       0.049105     98.00          2.473950          2.473950  0.01\n",
              "2      2       0.039668     98.48          2.252508          4.726458  0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbLhKZpkdW3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "outputId": "2dd295ed-21d7-4acd-e068-929c3ba39730"
      },
      "source": [
        "seed_experiment(42)\n",
        "use_half_all=True\n",
        "results_df = run_experiment(MAX_EPOCHS=3)\n",
        "use_half_all=False\n",
        "results_df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeded everything with seed: 42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Accuracy of     0 : 94 %\n",
            "INFO:root:Accuracy of     1 :  0 %\n",
            "INFO:root:Accuracy of     2 :  0 %\n",
            "INFO:root:Accuracy of     3 :  0 %\n",
            "INFO:root:Accuracy of     4 :  0 %\n",
            "INFO:root:Accuracy of     5 :  0 %\n",
            "INFO:root:Accuracy of     6 :  9 %\n",
            "INFO:root:Accuracy of     7 :  0 %\n",
            "INFO:root:Accuracy of     8 :  0 %\n",
            "INFO:root:Accuracy of     9 :  0 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0002, Accuracy: 1019/10000 (10%)\n",
            "\n",
            "INFO:root:Train Epoch: 1 [0 (0%)]\tLoss: 2.296875\n",
            "INFO:root:Train Epoch: 1 [32000 (53%)]\tLoss: 0.077881\n",
            "INFO:root:Accuracy of     0 : 98 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 99 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 99 %\n",
            "INFO:root:Accuracy of     5 : 97 %\n",
            "INFO:root:Accuracy of     6 : 98 %\n",
            "INFO:root:Accuracy of     7 : 96 %\n",
            "INFO:root:Accuracy of     8 : 97 %\n",
            "INFO:root:Accuracy of     9 : 95 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "INFO:root:Train Epoch: 2 [0 (0%)]\tLoss: 0.016678\n",
            "INFO:root:Train Epoch: 2 [32000 (53%)]\tLoss: 0.035736\n",
            "INFO:root:Accuracy of     0 : 99 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 98 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 98 %\n",
            "INFO:root:Accuracy of     5 : 98 %\n",
            "INFO:root:Accuracy of     6 : 98 %\n",
            "INFO:root:Accuracy of     7 : 97 %\n",
            "INFO:root:Accuracy of     8 : 98 %\n",
            "INFO:root:Accuracy of     9 : 98 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9860/10000 (99%)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>epoch_train_time</th>\n",
              "      <th>total_train_time</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>10.19</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.026733</td>\n",
              "      <td>98.01</td>\n",
              "      <td>2.658417</td>\n",
              "      <td>2.658417</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.043640</td>\n",
              "      <td>98.60</td>\n",
              "      <td>2.525256</td>\n",
              "      <td>5.183673</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  training_loss  test_acc  epoch_train_time  total_train_time    lr\n",
              "0      0      -1.000000     10.19         -1.000000         -1.000000 -1.00\n",
              "1      1       0.026733     98.01          2.658417          2.658417  0.01\n",
              "2      2       0.043640     98.60          2.525256          5.183673  0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1X7XnJgdj5s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzfGAV3duOsh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "outputId": "7896a9b7-f68b-447e-f46d-0ba7ac1f611a"
      },
      "source": [
        "seed_experiment(42)\n",
        "use_amp=True\n",
        "results_df = run_experiment(MAX_EPOCHS=3)\n",
        "use_amp=False\n",
        "results_df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeded everything with seed: 42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Accuracy of     0 : 94 %\n",
            "INFO:root:Accuracy of     1 :  0 %\n",
            "INFO:root:Accuracy of     2 :  0 %\n",
            "INFO:root:Accuracy of     3 :  0 %\n",
            "INFO:root:Accuracy of     4 :  0 %\n",
            "INFO:root:Accuracy of     5 :  0 %\n",
            "INFO:root:Accuracy of     6 :  9 %\n",
            "INFO:root:Accuracy of     7 :  0 %\n",
            "INFO:root:Accuracy of     8 :  0 %\n",
            "INFO:root:Accuracy of     9 :  0 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0002, Accuracy: 1020/10000 (10%)\n",
            "\n",
            "INFO:root:Train Epoch: 1 [0 (0%)]\tLoss: 2.296605\n",
            "INFO:root:Train Epoch: 1 [32000 (53%)]\tLoss: 0.095095\n",
            "INFO:root:Accuracy of     0 : 98 %\n",
            "INFO:root:Accuracy of     1 : 99 %\n",
            "INFO:root:Accuracy of     2 : 98 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 99 %\n",
            "INFO:root:Accuracy of     5 : 96 %\n",
            "INFO:root:Accuracy of     6 : 98 %\n",
            "INFO:root:Accuracy of     7 : 97 %\n",
            "INFO:root:Accuracy of     8 : 96 %\n",
            "INFO:root:Accuracy of     9 : 95 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9783/10000 (98%)\n",
            "\n",
            "INFO:root:Train Epoch: 2 [0 (0%)]\tLoss: 0.013767\n",
            "INFO:root:Train Epoch: 2 [32000 (53%)]\tLoss: 0.027876\n",
            "INFO:root:Accuracy of     0 : 99 %\n",
            "INFO:root:Accuracy of     1 : 98 %\n",
            "INFO:root:Accuracy of     2 : 99 %\n",
            "INFO:root:Accuracy of     3 : 98 %\n",
            "INFO:root:Accuracy of     4 : 98 %\n",
            "INFO:root:Accuracy of     5 : 98 %\n",
            "INFO:root:Accuracy of     6 : 98 %\n",
            "INFO:root:Accuracy of     7 : 97 %\n",
            "INFO:root:Accuracy of     8 : 98 %\n",
            "INFO:root:Accuracy of     9 : 97 %\n",
            "INFO:root:\n",
            "Test set: Average loss: 0.0000, Accuracy: 9850/10000 (98%)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>epoch_train_time</th>\n",
              "      <th>total_train_time</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>10.20</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.051643</td>\n",
              "      <td>97.83</td>\n",
              "      <td>3.481856</td>\n",
              "      <td>3.481856</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.018308</td>\n",
              "      <td>98.50</td>\n",
              "      <td>3.600611</td>\n",
              "      <td>7.082467</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  training_loss  test_acc  epoch_train_time  total_train_time    lr\n",
              "0      0      -1.000000     10.20         -1.000000         -1.000000 -1.00\n",
              "1      1       0.051643     97.83          3.481856          3.481856  0.01\n",
              "2      2       0.018308     98.50          3.600611          7.082467  0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzxYDPIBsswc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}